---
title: "Who do we think we are?"
knit: (function(input_file, encoding) {
  out_dir <- 'docs';
  rmarkdown::render(input_file,
 encoding=encoding,
 output_file=file.path(dirname(input_file), out_dir, 'index.html'))})
author: "Kelly Tall"
date: "15/08/2020"


output: 
        html_document:
                df_print: paged  
                toc: true
                toc_float: true      
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# install.packages("WikidataR")
# install.packages("WikipediR")
# install.packages("tidyverse")
# install.packages("rlist")
# install.packages("WikidataQueryServiceR")


library(tidyverse)
library(rlist)
library(ggplot2)
library(plotly)
library(scales)
library(lubridate)





##below data loads are not final data set, but kept here for the OLD-summarey of process section. Possible to be deleted at later stage
# New Data set after Alex work on data merging etc 7th September

##full OA st using Alex's extraction that also incudes gender
OAList <- read_csv("OAList.csv")

##all awards matched with wikipedia pages

allWP <- read_csv("allWP.csv")


##all data matched together
allData <- read_csv("allData.csv")


# load data ---------------------------------------------------------------

##honours data sets
OAqBday <- read_csv("OA_QueenBDay.csv")
OAausDay <- read_csv("OA_AusDay.csv")

##honours list merged
OAFullList <- bind_rows(OAqBday, OAausDay)

##match with wikidata
wikidataMatch <- read_csv("wikidataMatch.csv") %>% 
  select(-X1)


##Australian match with wikidata
wikidataAusMatch <- read_csv("wikidataAusMatch.csv")

##match with wikipedia

wikipediaMatch <- read_csv("wikipediaMatch.csv") 



pageCreation <- read_csv("pageCreation.csv")
  
##all data merge as of 19 August

allData <- read_csv("allData.csv")

```

## Project Summary and Aims

The two core analysis aims are:

to do: add in text from Heather's outline


## Overview of Dataset Preparation

 **to finish 

Initially data was matched using an extraction from the Australian Honours List, and then matched back to wikiedia and wikipedia (see section below - TO DO - ADD LINK). 

Once initial analysis was done, Alex Lum assisted in providing an extraction of wikipedia pages where an order was stated on the page. This led to the Order information being merged back into the wikidata page. This allowed us to extract further wikipedia pages. No additional pages have been created in wikipedia, but we have been able to get a bettr



### Honours Data Set

The Department of the Prime Minster and Cabinet <a href="https://honours.pmc.gov.au/honours/search">publish a list of Australian Honours recipients</a>. This list includes all recipients of the Order of Australia. 

The records were extracted from this database for all of the Order of Australia Awards issued since 1975, and extracted based on the following award levels:
        
1. Dame of the Order of Australia 
2. Knight of the Order of Australia  
3. Companion (AC) 
4. Officer (AO) 
5. Member (AM) 
6. Medal (OAM) 

More information about the Order of Australia can be found here: https://en.wikipedia.org/wiki/Order_of_Australia.

While the majority of cases are unique, there are some individuals who have been awarded multiple Orders of Australia. In the analysis shown below, all analysis that references the Honours data set, represents the number and type of awards issued. The number of awards in our data set ar XXXXinsert here###. These awards have been given to XXX individuals.
A summary of the number of awards given to indivisuals is as follows

(<em>show summary of number of awards by number of people</em>)


### Matching the honours data set with wikimedia information

<b>expand on  pr0cess here</b>

1. extract data from wikidata, icluding wikidata URL/ID and wikipedia URL
2. get wikipedia page ID for all wikipedia articles
3. use ID to etxract page creation date





## Exploratory analysis

#### Overview of Order of Australia honours
1. How many have been awarded?

2. What is the breakdown by state?

```{r echo=FALSE, message=FALSE, warning=FALSE}
##chart formats

colours <- c("#2d4059", "#ea5455")

custom_theme <-  theme(
                        panel.grid.major.x = element_blank(),
                        panel.background = element_rect(fill=("#e5e5e5")),
                        strip.background = element_blank())



awardSummaryTotal <- allData %>%
        select(award) %>%
        group_by(award) %>%
        tally()

awardSummaryState <- allData %>%
        select(award, state) %>%
        group_by(state, award ) %>%
        tally()
# 


awardTotal <-  ggplot(awardSummaryTotal, aes(reorder(award, -n), n))+
  geom_col(fill="#2d4059") +
  custom_theme+
  labs(title="Number of award recipients by level of membership",
       x="Order of Australia (membership levels)", y="number of awards")

ggplotly(awardTotal, tooltip="n")

awardState <- ggplot(awardSummaryState, aes(reorder(award, -n), n))+
  geom_col(fill="#2d4059") +
  facet_wrap(~state)+
  custom_theme+
  labs(title="Number of award recipients by level of membership by state",
       x="Order of Australia (membership levels)", y="number of awards")


ggplotly(awardState, tooltip = "n")


```


#### How many wikipedia pages are there for Order of Australia recipients?

1. What are the proportion Order of Australia recipients who have a wikipedia page?

2. What are the differences by the order level?

3. Are there any differences by recipient state?

```{r echo=FALSE, message=FALSE}

pagePropTotal <- allData %>% 
        select(award, wpPage) %>% 
        group_by(award, wpPage) %>% 
        tally()

pagePropState <- allData %>% 
        select(award, wpPage, state) %>% 
        group_by(award, wpPage, state) %>% 
        tally()



awardWPNum <- ggplot(pagePropTotal, aes(reorder(award, -n), n)) +
  geom_col(aes(fill=wpPage)) +
  custom_theme+
  labs(title="Number of award recipients that have a wikipedia article page", 
       x="Order of Australia (membership levels)", y="number of awards") +
  scale_fill_manual(values=colours)
  
  

ggplotly(awardWPNum, tooltip = "n")


awardWPNumState <- ggplot(pagePropState, aes(reorder(award, -n), n)) +
  geom_col(aes(fill=wpPage)) +
  facet_wrap(~state)+
  custom_theme+
  labs(title="Number of award recipients that have a wikipedia article page by state", 
       x="Order of Australia (membership levels)", y="number of awards")+
  scale_fill_manual(values=colours)

  

ggplotly(awardWPNumState, tooltip = "n")

awardWPProp <- ggplot(pagePropTotal, aes(reorder(award, -n), n, fill=wpPage)) +
  geom_bar(position="fill", stat="identity") +
  custom_theme+
  labs(title="Proportion of award recipients that have a wikipedia article page", 
       x="Order of Australia (membership levels)", y="number of awards") +
  scale_y_continuous(labels = percent)+
  scale_fill_manual(values=colours)
  
        
ggplotly(awardWPProp, tooltip="n")

awardWPPropState <- ggplot(pagePropState, aes(reorder(award, n), n, fill=wpPage)) +
        geom_bar(position="fill", stat="identity") +
        facet_wrap(~state)+
        custom_theme+
        labs(title="Proportion of award recipients that have a wikipedia article page by state", 
       x="Order of Australia (membership levels)", y="number of awards") +
  scale_y_continuous(labels = percent)+
  scale_fill_manual(values=colours)
  

ggplotly(awardWPPropState, tooltip="n")


```

#### What can we learn about the page creation date of those who have a wikipedia page?


1. How many had pages BEFORE or AFTER they received their Order of Australia? Is this different by order level?

2. Does receiving an order result in a spike of wikipedia pages being created?

3. What is the rate of creation of pages? Has there been peaks? Has it slowed at any time?


```{r echo=FALSE, message=FALSE}
prePost <- allData %>%
  filter(wpPage=="Yes") %>% 
  filter(prePost!="No wiki") %>% 
  select(prePost) %>% 
  group_by(prePost) %>% 
  tally()

awardprePost <- ggplot(prePost, aes(prePost, n)) +
  geom_col() +
  custom_theme+
  labs(title="Number of pages crated pre / post award", 
       y="number of wikiPedia Articles") +
  scale_fill_manual(values=colours)
  
  

ggplotly(awardprePost, tooltip = "n")

```





## Random notes
<i> These are just small things I find along the way that may not be that important, but are intersting or that I need to follow up on </i>

* Is there a big proportion of rugby and badmington players who have wikidata entries? (could be good to do some alaysis on this sort of thing / proportion of representation by description in wikiData) 
<br>
* Have gender in data set - checing with Alex on if there is way for broader gender classification
<br>
* How to handle peopel with multiple awards - multiple honour dates to single page creation date
<br>
* Need to find the entry of the nursing accadmic who is referenced in wikipedia page, but has no page of her own / has a wikidata entry (create list of these poeple to have a look and see who they are)
<br> 
* I think I found a few folks that had non eng wikipedia pages (think one was the Producer of shine? - need to check) Is this of interest? Possibly only a v small number. Could scrape the non english pages to see where they have page. (Also - what Australian's in general have been given page in other languages?)
<br> 
* Can I do some "bag of word" analysis on the award description and see if there are any areas that result in more page creations than others? (scientists v politicians v sorts people etc? see point above about representation in decsription of wikidata as well) 
<br>

### OLD - Summary of process  

1. Extracted all Order of Australia records from <a href="https://honours.pmc.gov.au/honours/search">The Australian Honours Search Facility</a><br>
2. Matched names of award recipients with all wikidata records using R package <a href="https://cran.r-project.org/web/packages/WikidataR/WikidataR.pdf">wikidataR</a>. This yielded TO DO: (insert # of records)<br>
3. sorted all matches into three "buckets" <br> 
   i) all items that have some "Australianess" in their decsription 
   ii) all items that have "not-Australianess" in their description 
   iii) all items that have neither "Australianess" or "not-Australianess" in their description  
4. Items in the "neither" bucket where manually checked to see if they were a match to an Order of Australian recipient and moved either into the "Australianess" bucket or the "not-Australianess" <br> 
5. Dupliacte records were then extracted from the "Australianess" bucket, were a name from the Order of Australia list was matched with a name of two or more wikidata entries. This was sorted manually by comparing the description from wikidata with the description of the merit. <br> 
6. Part of the "Australianess" bucket was then tested for errors. Again, the description from wikidata was compared against the descipriton of the award from the
Order of Australia list. From 100 enries selected, there were five incorrectly matched, and these were removed. <br> 
7. This list was then finalised, and the wikidataID was used in a scraper to extract the linked wikipedia article and article ID from wikidata <b>TO DO: need to check wiht Prue or Toby: is assumption correct that if a wikipedia page exists, there will be a wikidata entry, AND there will be a wikipedia page listed in the wikidata record)</b> <br> 
8. The edits of each matched wikipedia page were then scraped to extract the page creation date <br> 

<b>To do: insert table showing tally of records for each stage</b>

Of the <b>`r nrow(OAFullList)`</b> records extracted from the honours data base, the match with a wikiData extry with a connection to Australia was <b>`r nrow(wikidataAusMatch)`</b>. 

Once this was filtered for matches to a wikipedia page, there was a match of <b>`r nrow(wikipediaMatch)`</b> articles


#### Honours Data source and Extraction 

The honours data set was downloaded from <a href="https://honours.pmc.gov.au/honours/search">The Australian Honours Search Facility</a> published by the Department of the Prime Minster and Cabinet.

The records were extracted from this database for all of the Order of Australia Awards issued since 1975, and extracted based on the following award levels:
        
1. Dame of the Order of Australia 
2. Knight of the Order of Australia  
3. Companion (AC) 
4. Officer (AO) 
5. Member (AM) 
6. Medal (OAM) 

More information about the Order of Australia can be found here: https://en.wikipedia.org/wiki/Order_of_Australia

The data set represents a total of <b>`r nrow(OAFullList)`</b> hounours with each row of the data set an individual reward recipient.

The data variables in our set are:

```{r , echo=FALSE}
colnames(OAFullList)

```

The data extracted is shown for the first few rows of the data set as below:

```{r echo=FALSE, rows.print=7}
head(OAFullList)
```


####  Merging Honours with Wikidata information

Names of Order of Australia recipients were then passed through wikidata to gather more information, such as description of the person and their aliases. 

The reason for this was to ensure that names (normally awarded to the recipient with their full name), could also be matched to any other names they are known by. The query was run using an R package (<a href="https://cran.r-project.org/web/packages/WikidataR/WikidataR.pdf">wikidataR</a>) that accesses the wikiData API and matches not only the name the award is given to, but also any alias that is listed in a wikiData entry.  For example, Bob Hawke is listed as;

<b>Bob Hawke</b>

* Description:
  + Australian politician, 23rd Prime Minister of Australia

* Also known as: 
  + Bob Hawke
  + The Honourable Bob Hawke
  + Robert James Lee "Bob" Hawke
  + Robertus Iacobus Lee Hawke (latin)
  + Robertus Hawke (latin)
  + 鮑勃·霍克 (chinese)
        
For his AC, he was named as "Mr Robert James Lee HAWKE". The API searches against his name and aliases to give us a match.

This match of Order of Australia recipients with a wikiData match returned the following information:

```{r echo=FALSE, cols.print =4 ,rows.print=7}
head(wikidataMatch)
```

The description provided in the wikidata record often incuded key words such as "Australian". Using these as a starting point, this data set was filtered to include any mention of "Australian", as well as other key words or phrases such as "Queensland", "Tasmania", "New South Wales" etc. Likewise, other words such as "United States", "Dutch", "Spanish" etc were excluded from the list in the absensce of an Australian related term. 

Once this filtering and matching was done based on the decsription field, there was a list of "unallocated" records that I sifted through manually, and allocated to the Australian list if there was a match. This was done using other information contained in the wikiData entry or in the Honours information.

A final edit was undertaken to remove cases that referred to other "non-person" items such as parks, ovals, reserves, artciles, discographies, filmographies, foundations etc that may have included the name of the award recipient. 

The information is displayed below showing the head of the data set.   

```{r echo=FALSE, cols.print =4 ,rows.print=7}
head(wikidataAusMatch)
```

#### Matching names to wikipedia pages

Using the list of Australian matches, the wikidata ID was used in a scraper to get the wikipedia page url and article ID from wikidata. This gave us <b>`r nrow(wikipediaMatch)`</b> wikipedia article links.


```{r echo=FALSE, cols.print =2 ,rows.print=7}
head(wikipediaMatch)
```


#### Extracting a page creation date  

Each wikipedia page match has also been linked to a page creation date.

https://en.wikipedia.org/w/api.php?action=query&prop=revisions&rvlimit=1&rvprop=timestamp&rvdir=newer&pageids=Q2075218 

The above query asks to sort all revisions from oldest to most recent, and pull top timestamp , for page ID 2352403. Using a loop function, this query was scarped using the wikipedia ID of each matched article, and the timstamp was recorded.  

(This query was found via a search on <a href="https://stackoverflow.com/questions/43898352/how-to-get-date-of-creation-of-wikipedia-page-by-api">stackoverflow</a> and I built a simple scraper to store the time stamp against the page id.) 

```{r echo=FALSE, cols.print =4 ,rows.print=7}
head(pageCreation)
```


#### Final data merge

All data sets were then merged together, into a final data set. 
Cases were merged using the following method:

1. a file was created that combined the wikidataID and the wikipedia Page ID, and inluce the scraed page creation date
2. a second file was created merging the Order of Australia data set and the wikidata information, which passed on the wikidataID.
3. the two files were merged together using wikidataID as the merge key



The variables included on the full data set are:
```{r echo=FALSE}

colnames(allData)

```


### Data set and process limitations

There are pros and cons to this method. It speeds up a manual process of checking if the matched records are Order of Australia award recipients. It also means that inadvertantly a record may have been included that may not have been an Order of Australia recipient, but had a name and text identifyer (such as "Australian", "Queensland" etc) match. 

For example Bob Smith has received an AM. He has no wikiData entry. Bob Smith does not have an AM, but has a wikiData entry and a description that says "Australian medical researcher". The second Bob Smith  will be included in the list that is matched to the wikipedia query, even though he has no award. If we also has a wikipedia page he will be included in the final data set.

If an award recipient's description included another country but did not mention "Australia" or other Australian related terms, it will not included in the list. For example Jane A Smith has a wikidata entry. She has receievd an OA. Her decription says "Italian-born artist". She would be excluded from our list based on the presence of "Italian" without an Australian qualifier. If Jane Smith has an OA and is described as an "Italian-born Australian artist" she is included on our list.

It is hypothesised that these examples are the exception rather than the rule, and the majorty of matching cases identified in process are correct. A manual check of approx 500 cases resulted in five match errors. 